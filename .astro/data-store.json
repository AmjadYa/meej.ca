[["Map",1,2,9,10],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.1.1","content-config-digest","52892818892996ca","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://meej.ca\",\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[]},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":\"shiki\",\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"responsiveImages\":false},\"legacy\":{\"collections\":false}}","project",["Map",11,12,29,30,56,57],"project-3",{"id":11,"data":13,"body":17,"filePath":18,"digest":19,"rendered":20},{"title":14,"description":15,"slug":11,"link":16},"Projection-Mapped Interactive String","Using lidar and a projector to play nice chords.","https://www.github.com/amjad","# My Project\r\n\r\nThis is a project.","src/data/project/project3.md","ed873862b3dd3baf",{"html":21,"metadata":22},"\u003Ch1 id=\"my-project\">My Project\u003C/h1>\n\u003Cp>This is a project.\u003C/p>",{"headings":23,"imagePaths":28,"frontmatter":13},[24],{"depth":25,"slug":26,"text":27},1,"my-project","My Project",[],"project-2",{"id":29,"data":31,"body":35,"filePath":36,"digest":37,"rendered":38},{"title":32,"description":33,"slug":29,"link":34},"Autonomous Mario Kart Robot","Driving around a perilous terrain, no one to help...","https://github.com/AmjadYa/Autonomous-Robot","\u003Cdiv class=\"flex gap-2\">\r\n    \u003Cvideo src=\"/videos/robot1.mp4\" style=\"max-height:400px ; aspect-ratio:1; object-fit:cover\" controls>\u003C/video>\r\n    \u003Cimg src=\"/images/robot_on_zipline.jpg\" style=\"max-height:400px ; aspect-ratio:1 ; object-fit:cover\">\r\n\u003C/div>\r\n\r\n\r\n\r\n## What happened to you?!\r\n\r\nThey told me it would be the hardest semester of my life. (They were right.)\r\n\r\nIn the summer of 2023, I had to build a robot that could navigate an obstacle course, collect coins off the ground, and complete laps for points with no human interference. Since we thought things weren't hard enough, our team was **one of two** to use the zipline to short-cut a part of the course.\r\n\r\nWe split the work up into three disciplines: Electrical, Hardware and Software and progressively integrated components together.\r\n\r\n## Electrical\r\n\r\n\u003Cdiv class=\"flex gap-2\">\r\n    \u003Cimg src=\"/images/h bridge.jpg\" style=\"max-height:400px ; aspect-ratio:1 ; object-fit:cover\">\r\n    \u003Cimg src=\"/images/wired up.jpg\" style=\"max-height:400px ; aspect-ratio:1 ; object-fit:cover\">\r\n\u003C/div>\r\n\r\n## Hardware\r\n\r\nWe had a drive base that relied on Ackerman steering, with a servo steering front wheels and DC motors driving backwheels. The chassis was made out of lasercut plywood and acrylic, and 3d printed parts. The zipline mechanism was designed so that the roller wheels interlock into each other like a zipper. This meant the reaction force from contact with the beam would help the claw stay shut. Once the robot touched the ground, that reaction component would disappear and we could safely open the claw again.\r\n\r\n\u003Cdiv class=\"flex gap-2\">\r\n    \u003Cimg src=\"/images/robotcad1.jpg\" style=\"max-height:400px ; aspect-ratio:1 ; object-fit:cover\">\r\n    \u003Cimg src=\"/images/robotcad2.jpg\" style=\"max-height:400px ; aspect-ratio:1 ; object-fit:cover\">\r\n\u003C/div>\r\n\r\n## Software / Firmware\r\n\r\nThis project was where I fell in love with firmware; it's fun turning abstract instructions into actions.\r\n\r\nWe did everything in Arduino. My favourite functionality was a convolution algorithm that processed input from a 1kHz infrared beacon at the end of the track. This allowed us to detect the light we wanted to follow amidst potential noise and other IR sources. The algo would sample and normalize IR data (from IR sensors attached at the front), then convolve it with a predefined 1kHz and threshold the resulting sum to decide if the beacon was detected.\r\n\r\nThe whole robot operated through a multi-stage loop: initially following IR signals then hard-coded 90 degree turns, PID steering up a ramp, ziplining down and restarting. Additionally, we used hardware interrupts to detect edges and executed maneuvers like backing up or making sharp turns before falling off the edge.\r\n\r\nPutting the code together and getting to see the fruits of all the hardware-labour was satisfying.\r\n\r\n\u003Csmall>Also... I wasn't very good at OOP yet so all the code was in one file. I'm better now I promise.\u003C/small>","src/data/project/project2.md","7abb2cec5a16b7fd",{"html":39,"metadata":40},"\u003Cdiv class=\"flex gap-2\">\n    \u003Cvideo src=\"/videos/robot1.mp4\" style=\"max-height:400px ; aspect-ratio:1; object-fit:cover\" controls>\u003C/video>\n    \u003Cimg src=\"/images/robot_on_zipline.jpg\" style=\"max-height:400px ; aspect-ratio:1 ; object-fit:cover\">\n\u003C/div>\n\u003Ch2 id=\"what-happened-to-you\">What happened to you?!\u003C/h2>\n\u003Cp>They told me it would be the hardest semester of my life. (They were right.)\u003C/p>\n\u003Cp>In the summer of 2023, I had to build a robot that could navigate an obstacle course, collect coins off the ground, and complete laps for points with no human interference. Since we thought things weren’t hard enough, our team was \u003Cstrong>one of two\u003C/strong> to use the zipline to short-cut a part of the course.\u003C/p>\n\u003Cp>We split the work up into three disciplines: Electrical, Hardware and Software and progressively integrated components together.\u003C/p>\n\u003Ch2 id=\"electrical\">Electrical\u003C/h2>\n\u003Cdiv class=\"flex gap-2\">\n    \u003Cimg src=\"/images/h bridge.jpg\" style=\"max-height:400px ; aspect-ratio:1 ; object-fit:cover\">\n    \u003Cimg src=\"/images/wired up.jpg\" style=\"max-height:400px ; aspect-ratio:1 ; object-fit:cover\">\n\u003C/div>\n\u003Ch2 id=\"hardware\">Hardware\u003C/h2>\n\u003Cp>We had a drive base that relied on Ackerman steering, with a servo steering front wheels and DC motors driving backwheels. The chassis was made out of lasercut plywood and acrylic, and 3d printed parts. The zipline mechanism was designed so that the roller wheels interlock into each other like a zipper. This meant the reaction force from contact with the beam would help the claw stay shut. Once the robot touched the ground, that reaction component would disappear and we could safely open the claw again.\u003C/p>\n\u003Cdiv class=\"flex gap-2\">\n    \u003Cimg src=\"/images/robotcad1.jpg\" style=\"max-height:400px ; aspect-ratio:1 ; object-fit:cover\">\n    \u003Cimg src=\"/images/robotcad2.jpg\" style=\"max-height:400px ; aspect-ratio:1 ; object-fit:cover\">\n\u003C/div>\n\u003Ch2 id=\"software--firmware\">Software / Firmware\u003C/h2>\n\u003Cp>This project was where I fell in love with firmware; it’s fun turning abstract instructions into actions.\u003C/p>\n\u003Cp>We did everything in Arduino. My favourite functionality was a convolution algorithm that processed input from a 1kHz infrared beacon at the end of the track. This allowed us to detect the light we wanted to follow amidst potential noise and other IR sources. The algo would sample and normalize IR data (from IR sensors attached at the front), then convolve it with a predefined 1kHz and threshold the resulting sum to decide if the beacon was detected.\u003C/p>\n\u003Cp>The whole robot operated through a multi-stage loop: initially following IR signals then hard-coded 90 degree turns, PID steering up a ramp, ziplining down and restarting. Additionally, we used hardware interrupts to detect edges and executed maneuvers like backing up or making sharp turns before falling off the edge.\u003C/p>\n\u003Cp>Putting the code together and getting to see the fruits of all the hardware-labour was satisfying.\u003C/p>\n\u003Cp>\u003Csmall>Also… I wasn’t very good at OOP yet so all the code was in one file. I’m better now I promise.\u003C/small>\u003C/p>",{"headings":41,"imagePaths":55,"frontmatter":31},[42,46,49,52],{"depth":43,"slug":44,"text":45},2,"what-happened-to-you","What happened to you?!",{"depth":43,"slug":47,"text":48},"electrical","Electrical",{"depth":43,"slug":50,"text":51},"hardware","Hardware",{"depth":43,"slug":53,"text":54},"software--firmware","Software / Firmware",[],"project-1",{"id":56,"data":58,"body":62,"filePath":63,"digest":64,"rendered":65},{"title":59,"description":60,"slug":56,"link":61},"CNN Letter Detecting ROS Sim","Teacher kept telling me that I'm just a neural network ;-;","https://github.com/AmjadYa/fizzcomp","## You should do your labs.\r\n\r\nThis project was the culmination of **eight** labs that gave us the necessary background to create a fully autonomous, line-following robot for the end of the semester. You can read a logbook I made for all the labs (and random thoughts) which I created [here](/public/pdfs/Amjad%20Yaghi%20individual%20logbook.pdf). \r\n\r\n## Key visuals:\r\n\r\n\u003Cdiv class=\"flex gap-2\">\r\n    \u003Cvideo src=\"/videos/robot1.mp4\" style=\"max-height:400px ; aspect-ratio:1; object-fit:cover\" controls>\u003C/video>\r\n    \u003Cimg src=\"/images/robot_on_zipline.jpg\" style=\"max-height:400px ; aspect-ratio:1 ; object-fit:cover\">\r\n\u003C/div>\r\n\r\n## Here's a full report of the experience:\r\n\r\n\u003Cobject class=\"my-auto\" data=\"/public/pdfs/ENPH353_FINAL_REPORT.pdf\" type=\"application/pdf\" width=\"100%\" height=\"700px\">\r\n    \u003Cembed src=\"/public/pdfs/ENPH353_FINAL_REPORT.pdf\">\r\n        \u003Cp>This browser does not support PDFs. Please download the PDF to view it: \u003Ca href=\"/public/pdfs/ENPH353_FINAL_REPORT.pdf\">Download PDF\u003C/a>.\u003C/p>\r\n    \u003C/embed>\r\n\u003C/object>","src/data/project/project1.md","d13553a365fd67d2",{"html":66,"metadata":67},"\u003Ch2 id=\"you-should-do-your-labs\">You should do your labs.\u003C/h2>\n\u003Cp>This project was the culmination of \u003Cstrong>eight\u003C/strong> labs that gave us the necessary background to create a fully autonomous, line-following robot for the end of the semester. You can read a logbook I made for all the labs (and random thoughts) which I created \u003Ca href=\"/public/pdfs/Amjad%20Yaghi%20individual%20logbook.pdf\">here\u003C/a>.\u003C/p>\n\u003Ch2 id=\"key-visuals\">Key visuals:\u003C/h2>\n\u003Cdiv class=\"flex gap-2\">\n    \u003Cvideo src=\"/videos/robot1.mp4\" style=\"max-height:400px ; aspect-ratio:1; object-fit:cover\" controls>\u003C/video>\n    \u003Cimg src=\"/images/robot_on_zipline.jpg\" style=\"max-height:400px ; aspect-ratio:1 ; object-fit:cover\">\n\u003C/div>\n\u003Ch2 id=\"heres-a-full-report-of-the-experience\">Here’s a full report of the experience:\u003C/h2>\n\u003Cobject class=\"my-auto\" data=\"/public/pdfs/ENPH353_FINAL_REPORT.pdf\" type=\"application/pdf\" width=\"100%\" height=\"700px\">\n    \u003Cembed src=\"/public/pdfs/ENPH353_FINAL_REPORT.pdf\">\n        \u003Cp>This browser does not support PDFs. Please download the PDF to view it: \u003Ca href=\"/public/pdfs/ENPH353_FINAL_REPORT.pdf\">Download PDF\u003C/a>.\u003C/p>\n    \n\u003C/object>",{"headings":68,"imagePaths":78,"frontmatter":58},[69,72,75],{"depth":43,"slug":70,"text":71},"you-should-do-your-labs","You should do your labs.",{"depth":43,"slug":73,"text":74},"key-visuals","Key visuals:",{"depth":43,"slug":76,"text":77},"heres-a-full-report-of-the-experience","Here’s a full report of the experience:",[]]